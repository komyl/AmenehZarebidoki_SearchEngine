{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30c6cb5-d836-4be6-b66c-68e9c28b9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, messagebox\n",
    "\n",
    "# Scraping functions (same as before)\n",
    "def scrape_wikipedia(search_term):\n",
    "    search_url = f'https://en.wikipedia.org/wiki/{search_term.replace(\" \", \"_\")}'\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title = soup.find('h1', id='firstHeading').text.strip()\n",
    "        first_paragraph = soup.find('p').text.strip()\n",
    "        return f\"üîç Wikipedia Page: {title}\\nIntroduction: {first_paragraph}\\nRead the full article here: {search_url}\\n\"\n",
    "    else:\n",
    "        return f\"Failed to retrieve the page for '{search_term}'. Status code: {response.status_code}\\n\"\n",
    "\n",
    "def scrape_arxiv(search_term, num_results=5):\n",
    "    search_url = f'https://arxiv.org/search/?query={search_term.replace(\" \", \"+\")}&searchtype=all&source=header'\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        papers = soup.find_all('li', class_='arxiv-result')\n",
    "        results = \"üìÑ arXiv Results:\\n\"\n",
    "        if papers:\n",
    "            for paper in papers[:num_results]:\n",
    "                title = paper.find('p', class_='title').text.strip()\n",
    "                link = \"https://arxiv.org\" + paper.find('a')['href']\n",
    "                results += f\"{title}\\n{link}\\n\"\n",
    "            return results\n",
    "        else:\n",
    "            return \"No papers found on arXiv.\\n\"\n",
    "    else:\n",
    "        return f\"Could not retrieve arXiv results. Status code: {response.status_code}\\n\"\n",
    "\n",
    "def scrape_google_scholar(search_term, num_results=5):\n",
    "    search_url = f'https://scholar.google.com/scholar?hl=en&q={search_term.replace(\" \", \"+\")}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        articles = soup.find_all('h3', class_='gs_rt')\n",
    "        results = \"üìö Google Scholar Results:\\n\"\n",
    "        if articles:\n",
    "            for article in articles[:num_results]:\n",
    "                title = article.find('a').text.strip()\n",
    "                link = article.find('a')['href'] if article.find('a')['href'].startswith('http') else None\n",
    "                results += f\"{title}\\n{link}\\n\"\n",
    "            return results\n",
    "        else:\n",
    "            return \"No articles found on Google Scholar.\\n\"\n",
    "    else:\n",
    "        return f\"Could not retrieve Google Scholar results. Status code: {response.status_code}\\n\"\n",
    "\n",
    "def scrape_pubmed(search_term, num_results=5):\n",
    "    search_url = f'https://pubmed.ncbi.nlm.nih.gov/?term={search_term.replace(\" \", \"+\")}'\n",
    "    response = requests.get(search_url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        articles = soup.find_all('a', class_='docsum-title')\n",
    "        results = \"üî¨ PubMed Results:\\n\"\n",
    "        if articles:\n",
    "            for article in articles[:num_results]:\n",
    "                title = article.text.strip()\n",
    "                link = \"https://pubmed.ncbi.nlm.nih.gov\" + article['href']\n",
    "                results += f\"{title}\\n{link}\\n\"\n",
    "            return results\n",
    "        else:\n",
    "            return \"No articles found on PubMed.\\n\"\n",
    "    else:\n",
    "        return f\"Could not retrieve PubMed results. Status code: {response.status_code}\\n\"\n",
    "\n",
    "def perform_search():\n",
    "    search_term = entry.get()\n",
    "    if search_term:\n",
    "        results_text.delete(1.0, tk.END)  # Clear previous results\n",
    "        results = \"\"\n",
    "        results += scrape_wikipedia(search_term)\n",
    "        results += scrape_arxiv(search_term)\n",
    "        results += scrape_google_scholar(search_term)\n",
    "        results += scrape_pubmed(search_term)\n",
    "        results_text.insert(tk.END, results)  # Insert new results\n",
    "    else:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter a search term.\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Amy's Search Engine\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "label = tk.Label(root, text=\"Enter a topic or keyword to search:\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "entry = tk.Entry(root, width=50)\n",
    "entry.pack(pady=5)\n",
    "\n",
    "search_button = tk.Button(root, text=\"Search\", command=perform_search)\n",
    "search_button.pack(pady=10)\n",
    "\n",
    "results_text = scrolledtext.ScrolledText(root, width=70, height=15)\n",
    "results_text.pack(pady=5)\n",
    "\n",
    "welcome_message = \"Hello! Welcome to Amy's Search Engine! We provide search capabilities across Wikipedia, Google Scholar, arXiv, and PubMed. Let‚Äôs have fun exploring your articles! If you want to improve this, feel free to check GitHub.\"\n",
    "results_text.insert(tk.END, welcome_message)  # Insert welcome message at start\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d48a9f0-a54b-437e-939a-645dba7b7722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
